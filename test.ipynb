{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:14:28.157731Z",
     "start_time": "2024-08-06T16:14:28.132808Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f1daea1655f0ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:10:54.753269Z",
     "start_time": "2024-08-06T16:10:54.721042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timm.models.vision_transformer import VisionTransformer\n",
    "import torch\n",
    "\n",
    "model = VisionTransformer(img_size=32, patch_size=4, num_classes=0, embed_dim=128, depth=4, num_heads=8, mlp_ratio=4)\n",
    "#print(model)\n",
    "\n",
    "x = torch.randn(32, 3, 32, 32)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87333db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 128])\n"
     ]
    }
   ],
   "source": [
    "from timm.layers.patch_dropout import PatchDropout\n",
    "from vitssm.models.modules import LearnablePositionalEncoding\n",
    "import torch\n",
    "\n",
    "drop = PatchDropout(num_prefix_tokens=0)\n",
    "pos_enc = LearnablePositionalEncoding(16**2, 128, p_dropout=0.5)\n",
    "\n",
    "x = torch.ones((32, 32**2, 128))\n",
    "\n",
    "x = pos_enc(x)\n",
    "x = drop(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2097ec70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(x // 16 for x in (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5f72e35eb0fecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:00:40.422223Z",
     "start_time": "2024-08-06T16:00:40.415757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MultiHeadDispatch(\n",
       "    (attention): LocalAttention(\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (in_proj_container): InputProjection(\n",
       "      (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (1): MultiHeadDispatch(\n",
       "    (attention): LocalAttention(\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (in_proj_container): InputProjection(\n",
       "      (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (2): MultiHeadDispatch(\n",
       "    (attention): LocalAttention(\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (in_proj_container): InputProjection(\n",
       "      (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (3): MultiHeadDispatch(\n",
       "    (attention): LocalAttention(\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (in_proj_container): InputProjection(\n",
       "      (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (resid_drop): Dropout(p=0.0, inplace=False)\n",
       "    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xformers.components.multi_head_dispatch import MultiHeadDispatch\n",
    "from xformers.components.attention import ScaledDotProduct, LocalAttention\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#att = ScaledDotProduct(causal=True, seq_len=30)\n",
    "att = LocalAttention(causal=True, window_size=5)\n",
    "blocks = nn.Sequential(*(MultiHeadDispatch(128, 4, att) for _ in range(4)))\n",
    "\n",
    "x = torch.randn(32, 30, 128)\n",
    "\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd1d26c9913d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T15:02:49.026402Z",
     "start_time": "2024-08-06T15:02:48.996449Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [32, 30] but got: [32, 40].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m v \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones((\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m40\u001B[39m, \u001B[38;5;241m128\u001B[39m))\n\u001B[1;32m     14\u001B[0m mask \u001B[38;5;241m=\u001B[39m LowerTriangularMask()\n\u001B[0;32m---> 16\u001B[0m \u001B[43matt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/xformers/components/attention/scaled_dot_product.py:131\u001B[0m, in \u001B[0;36mScaledDotProduct.forward\u001B[0;34m(self, q, k, v, att_mask, *args, **kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;66;03m# Attend: (B x nh, S, hs) x (B x nh, hs, S) -> (B x nh, S, S)\u001B[39;00m\n\u001B[0;32m--> 131\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mscaled_dot_product_attention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43matt_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43matt_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn_drop\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/xformers/components/attention/core.py:331\u001B[0m, in \u001B[0;36mscaled_dot_product_attention\u001B[0;34m(q, k, v, att_mask, dropout, block_size)\u001B[0m\n\u001B[1;32m    327\u001B[0m     att \u001B[38;5;241m=\u001B[39m _apply_dropout(att, dropout)\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;66;03m# Get to the predicted values, for all heads\u001B[39;00m\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;66;03m# y = att @ v  # (N, S, S) x (N, S, hs) -> (N, S, hs)\u001B[39;00m\n\u001B[0;32m--> 331\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mbmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43matt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/xformers/components/attention/core.py:168\u001B[0m, in \u001B[0;36mbmm\u001B[0;34m(a, b)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mis_sparse:\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _sparse_bmm(a, b)\n\u001B[0;32m--> 168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected size for first two dimensions of batch2 tensor to be: [32, 30] but got: [32, 40]."
     ]
    }
   ],
   "source": [
    "from xformers.components.attention import ScaledDotProduct\n",
    "from xformers.ops.fmha.attn_bias import LowerTriangularMask\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "att = ScaledDotProduct(seq_len=30, to_seq_len=40)\n",
    "q_proj = nn.Linear(128, 128)\n",
    "k_proj = nn.Linear(128, 128)\n",
    "v_proj = nn.Linear(128, 128)\n",
    "\n",
    "q = torch.ones((32, 30, 128))\n",
    "k = torch.ones((32, 30, 128))\n",
    "v = torch.ones((32, 40, 128))\n",
    "mask = LowerTriangularMask()\n",
    "\n",
    "att(q_proj(q), k_proj(k), v_proj(v), mask=mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aee116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 3, 32, 32])\n",
      "torch.Size([960, 128, 8, 8])\n",
      "torch.Size([960, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "from vitssm.models.next_frame_prediction import LatentNextFramePrediction\n",
    "from xformers.components.positional_embedding import SinePositionalEmbedding\n",
    "import xformers\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "patchify = nn.Conv2d(3, 128, kernel_size=4, stride=4)\n",
    "pos_enc = SinePositionalEmbedding(128)\n",
    "\n",
    "x = torch.zeros((32, 30, 32, 32, 3))\n",
    "b, t, h, w, c = x.shape\n",
    "x = rearrange(x, \"b t h w c -> (b t) c h w\")\n",
    "print(x.shape)\n",
    "x = patchify(x)\n",
    "print(x.shape)\n",
    "x = rearrange(x, \"(b t) e h w -> (b t) (h w) e\", b=b, t=t)\n",
    "print(x.shape)\n",
    "x = pos_enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbe1baed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T05:07:04.092454Z",
     "start_time": "2024-08-07T05:07:04.065846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False],\n",
      "         [False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "from xformers.components.positional_embedding import SinePositionalEmbedding\n",
    "from einops import rearrange\n",
    "\n",
    "pos_enc = SinePositionalEmbedding(3)\n",
    "\n",
    "x1 = torch.zeros((1, 1, 4, 4, 3))\n",
    "x2 = torch.zeros((1, 1, 8, 8, 3))\n",
    "b1, t1, h1, w1, c1 = x1.shape\n",
    "b2, t2, h2, w2, c2 = x2.shape\n",
    "\n",
    "x1 = rearrange(x1, \"b t h w c -> b (t h w) c\")\n",
    "x1 = pos_enc(x1)\n",
    "#x1 = rearrange(x1, \"b (t h w) c -> (b t) h w c\", b=b1, t=t1, h=h1, w=w1)\n",
    "\n",
    "x2 = rearrange(x2, \"b t h w c -> b (t h w) c\")\n",
    "x2 = pos_enc(x2)\n",
    "#x2 = rearrange(x2, \"b (t h w) c -> (b t) h w c\", b=b2, t=t2, h=h2, w=w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcc8165a63cb0864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T15:03:56.680410Z",
     "start_time": "2024-08-26T15:03:49.950998Z"
    }
   },
   "source": [
    "from vitssm.models.next_frame_prediction import LatentNextFramePrediction\n",
    "import torch\n",
    "\n",
    "model = LatentNextFramePrediction(frame_in_size=(32, 32), frame_out_size=(64, 64), patch_size=4, latent_dim=64, n_heads=4, n_frames=30)\n",
    "x = torch.randn(32, 30, 32, 32, 3)\n",
    "model(x)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/micromamba/envs/ViTSSM/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/david/micromamba/envs/ViTSSM/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "Triton is not available, some optimizations will not be enabled.\n",
      "This is just a warning: triton is not available\n",
      "Either FairScale or torch distributed is not available, MixtureOfExperts will not be exposed. Please install them if you would like to use MoE\n",
      "/home/david/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MultiHeadDispatch.forward() got an unexpected keyword argument 'q'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m LatentNextFramePrediction(frame_in_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m32\u001B[39m), frame_out_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m64\u001B[39m), patch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, latent_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, n_heads\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, n_frames\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m      5\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/c/Users/david/Desktop/ViTSSM/vitssm/models/next_frame_prediction.py:82\u001B[0m, in \u001B[0;36mLatentNextFramePrediction.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     79\u001B[0m x_next_latent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlatent_predictor(x_latent)\n\u001B[1;32m     81\u001B[0m canvas \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_enc_patches(torch\u001B[38;5;241m.\u001B[39mones(b, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_out_size[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_out_size[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlatent_dim))\n\u001B[0;32m---> 82\u001B[0m x_next_frame \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlatent_frame_decoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcanvas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_patches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_next_latent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     83\u001B[0m x_next_frame \u001B[38;5;241m=\u001B[39m rearrange(\n\u001B[1;32m     84\u001B[0m     x_next_frame,\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb (h w) c -> b h w c\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     86\u001B[0m     h\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_out_size[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m     87\u001B[0m     w\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframe_out_size[\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m     88\u001B[0m )\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x_next_frame\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/c/Users/david/Desktop/ViTSSM/vitssm/models/next_frame_prediction.py:189\u001B[0m, in \u001B[0;36mLatentFrameDecoder.forward\u001B[0;34m(self, x_query, x_patches, x_latent)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;124;03mInput dims:\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;124;03m    x_query: [batch, height * width, latent]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;124;03mOutput dims: [batch, time, height_out, width_out, channel]\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    184\u001B[0m inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_query\u001B[39m\u001B[38;5;124m\"\u001B[39m: x_query,\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_kv1\u001B[39m\u001B[38;5;124m\"\u001B[39m: x_patches,\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_kv2\u001B[39m\u001B[38;5;124m\"\u001B[39m: x_latent,\n\u001B[1;32m    188\u001B[0m }\n\u001B[0;32m--> 189\u001B[0m x_query, _, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x_query\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/c/Users/david/Desktop/ViTSSM/vitssm/models/modules.py:95\u001B[0m, in \u001B[0;36mMixedCrossAttentionBlock.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor]):\n\u001B[1;32m     94\u001B[0m     x_query, x_kv1, x_kv2 \u001B[38;5;241m=\u001B[39m inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_query\u001B[39m\u001B[38;5;124m\"\u001B[39m], inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_kv1\u001B[39m\u001B[38;5;124m\"\u001B[39m], inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_kv2\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m---> 95\u001B[0m     x_query \u001B[38;5;241m=\u001B[39m x_query \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_attention\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_kv1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_kv1\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     96\u001B[0m     x_query \u001B[38;5;241m=\u001B[39m x_query \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp1(x_query))\n\u001B[1;32m     98\u001B[0m     x_query \u001B[38;5;241m=\u001B[39m x_query \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm3(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_attention(q\u001B[38;5;241m=\u001B[39mx_query, k\u001B[38;5;241m=\u001B[39mx_kv2, v\u001B[38;5;241m=\u001B[39mx_kv2))\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/ViTSSM/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: MultiHeadDispatch.forward() got an unexpected keyword argument 'q'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T14:36:07.529893Z",
     "start_time": "2024-08-26T14:36:07.498967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "nn.activation"
   ],
   "id": "5908edd7edcea7ef",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[0;32m----> 2\u001B[0m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch.nn' has no attribute 'activation'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428d2302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.966629547095765"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb9250dc232ff44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T16:48:07.995713Z",
     "start_time": "2024-07-22T16:48:07.929197Z"
    }
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "base_config = OmegaConf.load(Path(\"run_configs\") / \"base_config.yml\")\n",
    "config = OmegaConf.load(Path(\"run_configs\") / \"config_run_1.yml\")\n",
    "conf = OmegaConf.merge(base_config, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98791ad321ba8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:56:58.895687Z",
     "start_time": "2024-07-30T04:56:50.901577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8),\n",
       " tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]],\n",
       " \n",
       " \n",
       "         [[[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MovingMNIST\n",
    "from vitssm.data.datasets import NextFrameDataset\n",
    "\n",
    "\n",
    "mnist = MovingMNIST(root=\"data\", split=\"train\", split_ratio=10, download=False)\n",
    "data = NextFrameDataset(mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c60daced68ba04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T04:57:37.194309Z",
     "start_time": "2024-07-30T04:57:37.184433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 1, 64, 64]) torch.Size([9, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][0].shape, data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487aa3bdbd767cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T16:48:08.019094Z",
     "start_time": "2024-07-22T16:48:08.008539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xformers\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b2d6e77dc7f912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T16:48:08.930310Z",
     "start_time": "2024-07-22T16:48:08.019842Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'addict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mvitssm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mengine\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maction_recognition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ActionRecognitionEngine\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpytorch/vision:v0.10.0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124malexnet\u001B[39m\u001B[38;5;124m'\u001B[39m, pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/mnt/c/Users/david/Documents/Uni/vitssm/vitssm/engine/__init__.py:15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m set_seeds\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_metric_container\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_dataloaders\n\u001B[1;32m     17\u001B[0m wandb\u001B[38;5;241m.\u001B[39mlogin()\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mModelEngine\u001B[39;00m:\n",
      "File \u001B[0;32m/mnt/c/Users/david/Documents/Uni/vitssm/vitssm/data/__init__.py:6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01maddict\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader, random_split\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Compose, Resize, ToImage, ToDtype, Normalize\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'addict'"
     ]
    }
   ],
   "source": [
    "from vitssm.engine.tasks import ActionRecognitionEngine\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "engine = ActionRecognitionEngine(model, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a01979edfaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vitssm.utils.metrics import MetricContainer\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "import torch\n",
    "\n",
    "x = torch.randn(100, 100)\n",
    "y = torch.randint(0, 2, (100, 100))\n",
    "metric_col(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d77fd87f203b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vitssm.engine import build_optimizer\n",
    "from addict import Dict\n",
    "from torch import nn\n",
    "\n",
    "config = Dict({\n",
    "    \"optimization\": {\n",
    "        \"optimizer\": {\n",
    "            \"name\": \"Adam\",\n",
    "            \"args\": {\n",
    "                \"lr\": 0.001,\n",
    "                \"weight_decay\": 0.0\n",
    "            }\n",
    "        }\n",
    "    }    \n",
    "})\n",
    "\n",
    "model = nn.Linear(10, 10)\n",
    "build_optimizer(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579710ed660610d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb498001513a97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vitssm.data import build_dataset\n",
    "from addict import Dict\n",
    "import kappaconfig as kc\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "config = kc.from_file_uri(Path(\"run_configs\") / \"base_config.yml\")\n",
    "print(config.keys())\n",
    "res = kc.DefaultResolver()\n",
    "config = Dict(res.resolve(config))\n",
    "\n",
    "dataset = build_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972fac984f68fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1000][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f623708d4b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0ac6bd1ed53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0a9cf007aff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0].permute(0, 2, 3, 1).repeat(1, 1, 1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb78a7e053d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import write_video\n",
    "\n",
    "write_video(\"test.mp4\", train_dataset[0].permute(0, 2, 3, 1).repeat(1, 1, 1, 3), fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
